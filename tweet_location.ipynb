{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Classifying Tweets\n",
    "\n",
    "In this project, I will use a Naive Bayes Classifier to find patterns in real tweets. There are given three files: `new_york.json`, `london.json`, and `paris.json`. These three files contain tweets that were gathered from those locations.\n",
    "\n",
    "The goal is to create a classification algorithm that can classify any tweet (or sentence) and predict whether that sentence came from New York, London, or Paris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "london_tweets = pd.read_json('london.json', lines=True)\n",
    "paris_tweets = pd.read_json('paris.json', lines=True)\n",
    "new_york_tweets = pd.read_json('new_york.json', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate the Data\n",
    "\n",
    "To begin, let's take a look at the data and answer few questions.\n",
    "\n",
    "    How many London tweets are there? How many Paris or New York ones are there?\n",
    "    What are the columns, or features, of a tweet?\n",
    "    What are the text of the 12th tweet in the New York dataset?\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4723\n",
      "Index(['created_at', 'id', 'id_str', 'text', 'display_text_range', 'source',\n",
      "       'truncated', 'in_reply_to_status_id', 'in_reply_to_status_id_str',\n",
      "       'in_reply_to_user_id', 'in_reply_to_user_id_str',\n",
      "       'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place',\n",
      "       'contributors', 'is_quote_status', 'extended_tweet', 'quote_count',\n",
      "       'reply_count', 'retweet_count', 'favorite_count', 'entities',\n",
      "       'favorited', 'retweeted', 'filter_level', 'lang', 'timestamp_ms',\n",
      "       'possibly_sensitive', 'quoted_status_id', 'quoted_status_id_str',\n",
      "       'quoted_status', 'quoted_status_permalink', 'extended_entities'],\n",
      "      dtype='object')\n",
      "created_at                                           2018-07-26 13:39:42+00:00\n",
      "id                                                         1022476558630572033\n",
      "id_str                                                     1022476558630572032\n",
      "text                         I saw this on the BBC and thought you should s...\n",
      "display_text_range                                                         NaN\n",
      "source                       <a href=\"http://twitter.com/download/android\" ...\n",
      "truncated                                                                False\n",
      "in_reply_to_status_id                                                      NaN\n",
      "in_reply_to_status_id_str                                                  NaN\n",
      "in_reply_to_user_id                                                        NaN\n",
      "in_reply_to_user_id_str                                                    NaN\n",
      "in_reply_to_screen_name                                                   None\n",
      "user                         {'id': 2256373299, 'id_str': '2256373299', 'na...\n",
      "geo                                                                       None\n",
      "coordinates                                                               None\n",
      "place                        {'id': '4f060a213b552e5f', 'url': 'https://api...\n",
      "contributors                                                               NaN\n",
      "is_quote_status                                                          False\n",
      "extended_tweet                                                             NaN\n",
      "quote_count                                                                  0\n",
      "reply_count                                                                  0\n",
      "retweet_count                                                                0\n",
      "favorite_count                                                               0\n",
      "entities                     {'hashtags': [], 'urls': [{'url': 'https://t.c...\n",
      "favorited                                                                False\n",
      "retweeted                                                                False\n",
      "filter_level                                                               low\n",
      "lang                                                                        en\n",
      "timestamp_ms                                        2018-07-26 13:39:42.930000\n",
      "possibly_sensitive                                                         0.0\n",
      "quoted_status_id                                                           NaN\n",
      "quoted_status_id_str                                                       NaN\n",
      "quoted_status                                                              NaN\n",
      "quoted_status_permalink                                                    NaN\n",
      "extended_entities                                                          NaN\n",
      "Name: 12, dtype: object\n",
      "Be best #ThursdayThoughts\n",
      "\n",
      "\n",
      "Number of Tweets in London: 5341\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(new_york_tweets))\n",
    "print(london_tweets.columns)\n",
    "\n",
    "print(london_tweets.loc[12])\n",
    "print(new_york_tweets.loc[12][\"text\"])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f'Number of Tweets in London: {len(london_tweets)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying using language: Naive Bayes Classifier\n",
    "\n",
    "We're going to create a Naive Bayes Classifier. Let's begin by looking at the way language is used differently in these three locations. Let's grab the text of all of the tweets and make it one big list. Then combine all three into a variable named `all_tweets`.\n",
    "\n",
    "Let's also make the labels associated with those tweets.\n",
    "`0` represents a New York tweet, `1`  represents a London tweet, and `2` represents a Paris tweet. Finish the definition of `labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list = [new_york_tweets, london_tweets, paris_tweets]\n",
    "\n",
    "all_tweets = []\n",
    "labels = []\n",
    "num = 0\n",
    "for tweets in tweets_list:\n",
    "    all_tweets += tweets['text'].tolist()\n",
    "    labels += [num] * len(tweets)\n",
    "    num += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a Training and Test Set\n",
    "\n",
    "We can now break our data into a training set and a test set. We'll use scikit-learn's `train_test_split` function to do this split. This function takes two required parameters: It takes the data, followed by the labels. Set the optional parameter `test_size` to be `0.2`. Finally, set the optional parameter `random_state` to `1`. This will make it so your data is split in the same way as the data in our solution code. \n",
    "\n",
    "This function returns 4 items in this order:\n",
    "1. The training data\n",
    "2. The testing data\n",
    "3. The training labels\n",
    "4. The testing labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10059\n",
      "2515\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(all_tweets, labels, test_size=0.2, random_state=1)\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the Count Vectors\n",
    "\n",
    "To use a Naive Bayes Classifier, we need to transform our lists of words into count vectors. Recall that this changes the sentence `\"I love New York, New York\"` into a list that contains:\n",
    "\n",
    "* Two `1`s because the words `\"I\"` and `\"love\"` each appear once.\n",
    "* Two `2`s because the words `\"New\"` and `\"York\"` each appear twice.\n",
    "* Many `0`s because every other word in the training set didn't appear at all.\n",
    "\n",
    "To start, create a `CountVectorizer` named `counter`.\n",
    "\n",
    "Next, call the `.fit()` method using `train_data` as a parameter. This teaches the counter our vocabulary.\n",
    "\n",
    "Finally, let's transform `train_data` and `test_data` into Count Vectors. Call `counter`'s `.transform()` method using `train_data` as a parameter and store the result in `train_counts`. Do the same for `test_data` and store the result in `test_counts`.\n",
    "\n",
    "Print `train_data[7]` and `train_counts[7]` to see what a tweet looks like as a Count Vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Despite this Iâ€™m still loving the heat btw ðŸŒž\n",
      "  (0, 4879)\t1\n",
      "  (0, 7847)\t1\n",
      "  (0, 12487)\t1\n",
      "  (0, 16565)\t1\n",
      "  (0, 25639)\t1\n",
      "  (0, 26698)\t1\n",
      "  (0, 26897)\t1\n"
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "counter = CountVectorizer()\n",
    "counter.fit(train_data)\n",
    "\n",
    "train_counts = counter.transform(train_data)\n",
    "test_counts = counter.transform(test_data)\n",
    "\n",
    "print(train_data[77])\n",
    "print(train_counts[77])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test the Naive Bayes Classifier\n",
    "\n",
    "We now have the inputs to our classifier. Let's use the CountVectors to train and test the Naive Bayes Classifier.\n",
    "\n",
    "First, make a `MultinomialNB` named `classifier`.\n",
    "\n",
    "Next, call `classifier`'s `.fit()` method. This method takes two parameters: the training data and the training labels. `train_counts` contains the training data and `train_labels` containts the labels for that data.\n",
    "\n",
    "Calling `.fit()` calculates all of the probabilities used in Bayes Theorem. The model is now ready to quickly predict the location of a new tweet. \n",
    "\n",
    "Finally, let's test our model. `classifier`'s `.predict()` method using `test_counts` as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_counts, train_labels)\n",
    "\n",
    "predictions = classifier.predict(test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Model\n",
    "\n",
    "Now that the classifier has made its predictions, let's see how well it did. Let's look at two different ways to do this. First, call scikit-learn's `accuracy_score` function. This prints the percentage of tweets in the test set that the classifier correctly classified.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6779324055666004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other way to evaluate model is by looking at the **confusion matrix**. A confusion matrix is a table that describes how your classifier made its predictions. For example, if there were two labels, A and B, a confusion matrix might look like this:\n",
    "\n",
    "```\n",
    "9 1\n",
    "3 5\n",
    "```\n",
    "\n",
    "In this example, the first row shows how the classifier classified the true A's. It guessed that 9 of them were A's and 1 of them was a B. The second row shows how the classifier did on the true B's. It guessed that 3 of them were A's and 5 of them were B's.\n",
    "\n",
    "In this project using tweets, there were three classes &mdash; `0` for New York, `1` for London, and `2` for Paris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[541 404  28]\n",
      " [203 824  34]\n",
      " [ 38 103 340]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Your Own Tweet\n",
    "\n",
    "The confusion matrix line up with intuition. The classifier predicts tweets that were actually from New York as either New York tweets or London tweets, but almost never Paris tweets. Similarly, the classifier rarely misclassifies the tweets that were actually from Paris. Tweets coming from two English speaking countries are harder to distinguish than tweets in different languages.\n",
    "\n",
    "Now it's your chance to write a tweet and see how the classifier works! I wrote `write_tweet` function which take text in string format as argument and print it's prediction.\n",
    "Remember a `0` represents New York, a `1` represents London, and a `2` represents Paris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[1]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "def write_tweet(text):\n",
    "    tweet = text\n",
    "    tweet_counts = counter.transform([tweet])\n",
    "    print(classifier.predict(tweet_counts))\n",
    "\n",
    "\n",
    "write_tweet('Je suis Bartek')\n",
    "write_tweet('Well it\\'s not you, who drink tea')\n",
    "write_tweet('New york rule')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e925636a0b7c6026e16ceba626bc40dea2d843d871da5cfe06b4755fd84dac6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

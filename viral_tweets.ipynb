{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Viral Tweets\n",
    "\n",
    "In this project, I am going to use the K-Nearest Neighbor algorithm to predict whether a tweet will go viral. Before jumping into using the classifier, let's first consider the problem we're trying to solve. Which features of a tweet are most closely linked to its popularity? Maybe the number of hashtags or the number of links in the tweet strongly influences its popularity. Maybe its virality is dependent on how many followers the person has. Maybe it's something more subtle like the specific language used in the tweets.\n",
    "\n",
    "Let's explore these options by looking at the data we have available to us. First let's answer few questions.\n",
    "\n",
    "* What the total number of tweets in the dataset?\n",
    "* What are the columns, or features, of the dataset?\n",
    "* What is the text of the first tweet in the dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11099\n",
      "Index(['created_at', 'id', 'id_str', 'text', 'truncated', 'entities',\n",
      "       'metadata', 'source', 'in_reply_to_status_id',\n",
      "       'in_reply_to_status_id_str', 'in_reply_to_user_id',\n",
      "       'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo',\n",
      "       'coordinates', 'place', 'contributors', 'retweeted_status',\n",
      "       'is_quote_status', 'retweet_count', 'favorite_count', 'favorited',\n",
      "       'retweeted', 'lang', 'possibly_sensitive', 'quoted_status_id',\n",
      "       'quoted_status_id_str', 'extended_entities', 'quoted_status',\n",
      "       'withheld_in_countries'],\n",
      "      dtype='object')\n",
      "RT @KWWLStormTrack7: We are more than a month into summer but the days are getting shorter. The sunrise is about 25 minutes later on July 3â€¦\n",
      "Waterloo, Iowa\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all_tweets = pd.read_json(\"random_tweets.json\", lines=True)\n",
    "\n",
    "print(len(all_tweets))\n",
    "print(all_tweets.columns)\n",
    "print(all_tweets.loc[0]['text'])\n",
    "\n",
    "print(all_tweets.loc[0]['user']['location'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Viral Tweets\n",
    "\n",
    "A K-Nearest Neighbor classifier is a supervised machine learning algorithm, and as a result, we need to have a dataset with tagged labels. For this specific example, we need a dataset where every tweet is marked as viral or not viral. Unfortunately, this isn't a feature of our dataset &mdash; we'll need to make it ourselves.\n",
    "\n",
    "So how do we define a viral tweet? A good place to start is to look at the number of retweets the tweet has. This can be found using the feature `\"retweet_count\"`. Let's say we wanted to create a column called `is_viral` that is a `1` if the tweet had more than `5` retweets and `0` otherwise. We could do that like this:\n",
    "\n",
    "```py\n",
    "all_tweets['is_viral'] = np.where(all_tweets['retweet_count'] > 5, 1, 0)\n",
    "```\n",
    "Instead of using `5` as the benchmark for a viral tweet, let's use the median number of retweets. \n",
    "\n",
    "\n",
    "After finishing this project, It is worth coming back and playing with this threshold number. Classifying is easier if classes are more distinct. If I define viral as above median, I can expect lower accuracy than if I would classify viral as top 10% tweets. At the end, let's see compare the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.0\n",
      "5003.0\n",
      "0    9988\n",
      "1    1111\n",
      "Name: is_viral, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "median_retweet = np.median(all_tweets['retweet_count'])\n",
    "top_10 = np.quantile(all_tweets['retweet_count'], 0.9)\n",
    "\n",
    "all_tweets['is_viral'] = np.where(all_tweets['retweet_count'] >= top_10, 1, 0)\n",
    "\n",
    "print(median_retweet)\n",
    "print(top_10)\n",
    "print(all_tweets['is_viral'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Features\n",
    "\n",
    "Now that we've created a label for every tweet in our dataset, we can begin thinking about which features might determine whether a tweet is viral. We can create new columns in our dataset to represent these features. For example, let's say we think the length of a tweet might be a valuable feature. The following line creates a new column containing the length of the tweet.\n",
    "\n",
    "```py\n",
    "all_tweets['tweet_length'] = all_tweets.apply(lambda tweet: len(tweet['text']), axis=1)\n",
    "```\n",
    "\n",
    "Setting `axis = 1` creates a new column rather than a new row.\n",
    "\n",
    "Create a new column called `followers_count` that contains the number of followers of each user. You can find this information in `tweet['user']['followers_count']`. Do the same for `friends_count`.\n",
    "\n",
    "For the rest of this project, we will be using these features.\n",
    "\n",
    "* The number of words in the tweet.\n",
    "* The number of hashtags in the tweet. \n",
    "* The number of links in the tweet. \n",
    "* THe number of followers.\n",
    "* The number of friends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets['tweet_length'] = all_tweets.apply(lambda tweet: len(tweet['text']), axis=1)\n",
    "all_tweets['followers_count'] = all_tweets.apply(lambda tweet: tweet['user']['followers_count'], axis=1)\n",
    "all_tweets['friends_count'] = all_tweets.apply(lambda tweet: tweet['user']['friends_count'], axis=1)\n",
    "all_tweets['hashtag_count'] = all_tweets.apply(lambda tweet: tweet['text'].count('#'), axis=1)\n",
    "all_tweets['link_count'] = all_tweets.apply(lambda tweet: tweet['text'].count('http'), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing The Data\n",
    "\n",
    "I've made the columns that I want to feed into my classifier. Let's get rid of all the data that is no longer relevant. Create a variable named `labels` and set it equal to the `'is_viral'` column of all_tweets.\n",
    "\n",
    "Now create a new variable named `scaled_features`. `scaled_features` should be the result of the `scale` function with `feature` as a parameter. Also include the parameter `axis = 0`. This scales the *columns* as opposed to the rows.\n",
    "\n",
    "The scale function will normalize the data so all of the features will vary within the same range.\n",
    "\n",
    "Print `scaled_data[0]` to get a sense of what our data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.6164054  -0.02878298 -0.14483305 -0.32045057 -0.78415588]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "labels = all_tweets['is_viral']\n",
    "features = all_tweets[['tweet_length', 'followers_count', 'friends_count', 'hashtag_count', 'link_count']]\n",
    "\n",
    "scaled_features = scale(features, axis=0)\n",
    "print(scaled_features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Training Set and Test Set\n",
    "\n",
    "To evaluate the effectiveness of our classifier, we now split `scaled_data` and `labels` into a training set and test set using scikit-learn's `train_test_split` function. This function takes two required parameters: It takes the data, followed by the labels. Set the optional parameter `test_size` to be `0.2`. Also set the `random_state` parameter so program will randomly split the data each time in the same way. This function returns 4 items in this order:\n",
    "\n",
    "1. The training data\n",
    "2. The testing data\n",
    "3. The training labels\n",
    "4. The testing labels\n",
    "\n",
    "Store the results in variables named `train_data`, `test_data`, `train_labels`, and `test_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Classifier\n",
    "\n",
    "Now I can finally use the K-Nearest Neighbor classifier. Let's test it using `k = 5`. Begin by creating a `KNeighborsClassifier` object named `classifier` with the parameter `n_neighbors` equal to `5`.\n",
    "\n",
    "Next, train `classifier` by calling the `.fit()` method with `train_data` and `train_labels` as parameters.\n",
    "\n",
    "Finally, let's test the model! Call `classifier`'s `.score()` method using `test_data` and `test_labels` as parameters. Print the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8873873873873874"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(train_data, train_labels)\n",
    "\n",
    "classifier.score(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing K\n",
    "\n",
    "We've tested our classifier with `k = 5`, but maybe there's a `k` that will work better. Let's test many different values for `k` and graph the results. \n",
    "\n",
    "First, create an empty list called `scores`. Next, create a for loop that has a variable `k` that begins at `1` and ends at `200`.\n",
    "\n",
    "Inside the for loop, create a `KNeighobrsClassifier` object named `classifier` with the parameter `n_neighbors` equal to `k`.\n",
    "\n",
    "Train `classifier` by calling the `.fit()` method with `train_data` and `train_labels` as parameters.\n",
    "\n",
    "Next, let's test the model. Call `classifier`'s `.score()` method using `test_data` and `test_labels` as parameters. `append` the result to `scores`.\n",
    "\n",
    "Finally, let's plot the results. Outside of the loop, use Matplotlib's `plot()` function. `plot()` takes two parameters &mdash; the data on the x-axis and the data on the y-axis. Data on the x-axis should be the values we used for `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAmM0lEQVR4nO3de5xddXnv8c83kwyBXLhOIyRcFQjxAmJMsSqiQS4KphatQS2SqpSWKOrRA96qLccerdJWDTUFS1GLIip4gqaC1XJRQBMgIRcSHcIlQxASwi0JJDOzn/PH+u1kzZ41k51x1t5j9vf9es0re932evaayXr277oUEZiZmdUa1ewAzMxsZHKCMDOzQk4QZmZWyAnCzMwKOUGYmVkhJwgzMyvkBGENI2mFpJN+j+ND0ouGLyIzG4wThA0LSTdK+vuC9bMk/U7S6Ih4cUTcXMK5V0jalH56JT2fW/7EcJ+v5tw3S3pfmecY5NyH5D7nppRAN+eWXztM55krabGkrZKuKtg+U9IqSVsk/Y+kQ3Pb3inpUUkP5L8cSHqhpNsltQ1HjFYOJwgbLlcBfyFJNev/Arg6InoGO1jS6KGeOCWe8RExHrgNmFtdjoh/GOr7jnQR8XDuc45Pq4/NrbttmE61Dvg/wJW1GyQdAFwHfBrYD1gMfDdtGw18Hjge+AAwL3foV4CPRETvMMVoJXCCsOHyQ7IbxPZvrZL2Bc4AvpmWH5R0cnr9WUnfl/Sfkp4BzpU0Q9Idkp5K3zrnSWofakCSHpL0ivT63ekb9rS0/D5JP0yvR0m6WNL9kp6QdK2k/XLvc0L6tvuUpKXVb8KSPpc+77z0jX2eMv8s6XFJT0u6V9JLBohvjqT7JD0raY2kv8ptO0DSj9I5N0q6TVLd/18l7S3pm5LWp+vwqerxks6V9EtJX00xrpI0c6D3iojrIuKHwBMFm/8MWBER34uI54HPAsdKmgrsDzwSEY8C/w0ckc7/trT+zno/jzWHE4QNi4h4DrgWOCe3+s+BVRGxdIDDZgHfB/YBrgZ6gQ8DBwCvAmYCf/N7hHULcFJ6fSKwBnhdbvmW9PqDwJ+mbQcBTwKXAUiaDPyY7Bv0fsBHgR9I6oiIT9K3xDIXOCW991Hpc72D4hsrwONkCXQiMAf4Z0nHp23/C+gCOoBJwCeAXZkX56vA3mQ35deR/V7m5Lb/cboeBwCfAa7LJ8Vd8GJg++83IjYD96f164H9JU0B3giskDQe+BTw8SGcyxrMCcKG0zeAt0vaMy2fk9YN5I6I+GFEVCLiuYi4KyLujIieiHgQ+Dd23NCH4pbc8a8F/m9u+XXsSBB/BXwyIroiYivZt+C3pSqSdwMLI2JhivOnZNUobxrgnN3ABGAqoIi4L32D7icifhwR90fmFuAmdpTAuoEDgUMjojsibos6J05L9frvAD4eEc+ma3kpWXVf1ePAv6T3/i6wGnhzPe9fYzzwdM26p4EJEVEB/prsS8BHgfcDf0+WvF6a2ituHKiEZc3nBGHDJiJ+QfatcZakI4BXAt8e5JC1+QVJR6Vqld+laqd/IPuGO1S3AK+V9AKgjaxu/NWSDiP7dr0k7XcocH2qznkKuI+sNDMpbXt7dVva/hqym3c/EfFzsrr2y4DHJF0uaWLRvpJOl3RnqkJ6iizpVD/vF4FO4KZU/XTxLnzuA4B24KHcuoeAybnlR2oSzkNkpaddtYmsBJQ3EXgWICJ+FhEnRMTrgAownay96lvAucAlwNeHcF5rACcIG27fJCs5/AVwU0Q8Nsi+td+IvwasAo6MiIlk1Sq1jd51i4hOYAtZFdKtEfEs8DvgPOAX6RsuZInq9IjYJ/czNiIeSdu+VbNtXER8foDPQER8JSJeQVbNchTwsdp9JO0B/AD4EjApIvYBFlY/b/rm/78i4gjgTOAjg7UT1NhAVgI5NLfuEOCR3PLkmg4Fh5A1Ru+qFcCx1QVJ44AXpvXk1osscX6QLIG1RcRDwCLgZUM4rzWAE4QNt28CJ5NVJwxWvVRkAvAMsCk1cv71MMRzCzCXHdVJN9csA8wHPlftnimpQ9KstO0/gTMlnSqpTdJYSSelenWAx0iNr+nYV0r6Y0ljgM3A82SlkVrtwB5kJa4eSaeTtV9U3+cMSS9KN9Zn0nvU1eMn9Qy6Nn2mCelzfSR9lqo/Aj4oaYyktwPHkCWofiSNljSWrBRWvQbVXmfXAy+RdFba52+BeyNiVc3bvA+4JyKWkLXJ7Jk6DLyerC3ERiAnCBtWqb77dmAcsGAXD/8o8E6y6okrSN0lf0+3kCWeWwdYBvgyWaw3SXoWuJOsEZeIWEvWmP4Jspv5WrISwajcsW+T9KSkr5BVr1xB1tD9ENnN8Eu1QaXSzAfJbuRPps+dv15HkvX82QTcAfzrLo4h+QBZgloD/IKsqi/fTfVX6RwbgM8Bb4uIgRrTPwU8B1xM1ibzXFpHRKwHzkrv8STZdZudP1hZV9gLybrCkro8zwV+TpacP7ALn8saSH5gkFlrkXQu8L6IeE2zY7GRzSUIMzMrVGqCkHSapNWSOot6YUjaV9L1aTDRr/Pd3XZ2rJmZlau0KqbUF/s3ZANkush6K5wdEStz+3wR2BQRf5caJS+LiJn1HGtmZuUqswQxA+iMiDURsQ24hqyxL28a8DOA1OvhMEmT6jzWzMxKNOQJ0uowmb4DobpIPUNylpLN5fILSTPI+m1PqfNYACSdR9avnXHjxr1i6tSpwxK8mVkruOuuuzZEREfRtjITRNEAp9r6rM8DX5a0BFgG3AP01HlstjLicuBygOnTp8fixYuHGq+ZWcuR9NBA28pMEF3AwbnlKdSM1IyIZ0gTiKUBQQ+kn712dqyZmZWrzDaIRcCRkg5XNmXzbGoGTknaRzumc34f2XQIz9RzrJmZlau0EkRE9EiaC9xINkT/yohYIen8tH0+2fD+b0rqBVYC7x3s2LJiNTOz/narkdRugzAz2zWS7oqI6UXbPJLazMwKOUGYmVkhJwgzMyvkBDGMfvvYs1y7eC2Vyu7TrmNmravMcRC7vXu7nuLJLd0ArN24hc/9+D6e6+7lJ8t/xzmvOpS+D+wyMyvHmDbxJy/8fZ7OW8wJYoiWP/I0b5n3yz7rXnHovrxx2iS+dONqfr7q8SZFZmat5oDxe7D4UycP+/s6QQzRN25/kL3a27jy3Fcypm0Uo0eJaQdNZEzbKM542YE89szWZodoZi1iTFs5tRVOEEPw5OZtLFi6jrNeMYUTjti/3/Yp++7FlH33akJkZmbDxwliF2zt6eWffvobVq57hq09Fc551aHNDsnMrDTuxbQTlUpw+/0biAhuv/8J/u2WNSx/5GlmHXcQU18wsdnhmZmVxiWInbhjzRO86+u/4lvvncHStU8hwW0XvYHxe/jSmdnuzXe5nXj06ecB+GXnE6z+3TO8qGO8k4OZtQRXMe3Exs1Zb6Q71jzBvV1Pc+zB+zQ3IDOzBvFX4Z14YtM2AJaufQqAY6fs3cRozMwaxyWInXhi87Y+yy5BmFmrcILYiY2bt3FExzjGtIn2tlHuuWRmLcNVTDvxxKatTN5nT14wcSw9vUH7aOdUM2sNThA78cTmbRzRMZ5PnzGNym709D0zs51xgtiJjZu3sd+4dvYb197sUMzMGqrU+hJJp0laLalT0sUF2/eWdIOkpZJWSJqT23ahpOVp/YfKjLPWpq09fOvOh9iyrYct23rZf7yTg5m1ntJKEJLagMuANwJdwCJJCyJiZW63C4CVEXGmpA5gtaSrgaOA9wMzgG3ATyT9OCJ+W1a8eT9f9Tif/uFy9tlzDAD7u/RgZi2ozBLEDKAzItZExDbgGmBWzT4BTFD2ZJ3xwEagBzgGuDMitkRED3AL8NYSY+1ja3cvALffvwGA/cbt0ahTm5mNGGUmiMnA2txyV1qXN48sGawDlgEXRkQFWA6cKGl/SXsBbwIOLjqJpPMkLZa0eP369cMS+LbeCpBNrwG4isnMWlKZCaLoCRa13YBOBZYABwHHAfMkTYyI+4AvAD8FfgIsJStZ9H/DiMsjYnpETO/o6BiWwLt7sgTx8MYtgKuYzKw1lZkguuj7rX8KWUkhbw5wXWQ6gQeAqQAR8e8RcXxEnEhW9dSQ9geA7t6+eWz/8a5iMrPWU2aCWAQcKelwSe3AbGBBzT4PAzMBJE0CjgbWpOU/Sv8eAvwZ8J0SY+2jWsUE0D56FOPa2xp1ajOzEaO0XkwR0SNpLnAj0AZcGRErJJ2fts8HLgGukrSMrErqoojYkN7iB5L2B7qBCyLiybJirdWdSxAHjGsna0M3M2stpQ6Ui4iFwMKadfNzr9cBpwxw7GvLjG0w+QSxnxuozaxFeSR1ge7eYOyYUew/bg/2dxdXM2tRThAFtvVUaG8bxRfOehnjx/oSmVlr8t2vQHdvhfbRo3jNkQc0OxQzs6bx3NUFunsrjGnzpTGz1ua7YIHu3nCCMLOW57tggW29Fca0uWurmbU2J4gC3T2uYjIz812wQLWR2syslfkumDzf3cu9XU8BboMwMwMniO0WLF3HW//1dp5+rtttEGZmOEFst3lrD72VYPPWHndzNTPDCWK73ko2xffWnkrWBuEEYWYtznfBJNIjILb29NLd4zYIMzPfBZPelCGe765kbRDuxWRmLc53waSSEsTW7l629biR2szMCSLZUcXkNggzM3CC2K62kdptEGbW6nwXTCrb2yB6PVDOzIySE4Sk0yStltQp6eKC7XtLukHSUkkrJM3JbftwWrdc0nckjS0z1kquBLHNU22YmZWXICS1AZcBpwPTgLMlTavZ7QJgZUQcC5wEXCqpXdJk4IPA9Ih4CdAGzC4rVoCUH1IJokK7G6nNrMWV+TV5BtAZEWsiYhtwDTCrZp8AJkgSMB7YCPSkbaOBPSWNBvYC1pUY6/Yqpue29RKBq5jMrOWVeRecDKzNLXeldXnzgGPIbv7LgAsjohIRjwBfAh4GHgWejoibik4i6TxJiyUtXr9+/ZCDrY6DePb5bgCPgzCzllfmXbCojiZqlk8FlgAHAccB8yRNlLQvWWnj8LRtnKR3F50kIi6PiOkRMb2jo2PIwVa7uT67NSvAuARhZq2uzLtgF3BwbnkK/auJ5gDXRaYTeACYCpwMPBAR6yOiG7gO+JMSY93ezXXT81mCcBuEmbW6MhPEIuBISYdLaidrZF5Qs8/DwEwASZOAo4E1af0JkvZK7RMzgftKjHV7G8QmlyDMzICsIbgUEdEjaS5wI1kvpCsjYoWk89P2+cAlwFWSlpFVSV0UERuADZK+D9xN1mh9D3B5WbFm8WT/Pvu8E4SZGZSYIAAiYiGwsGbd/NzrdcApAxz7GeAzZcaXV61i2t4G4UZqM2txvgsm26uYUi8mt0GYWatzgkiqA+XcBmFmlvFdMKlOteE2CDOzjO+CSbWKacu2XsAJwszMd8GkOpK6qn202yDMrLU5QSQ1+cElCDNreb4LJpWaDOEEYWatznfBpDoOosoJwsxane+CSW0Vk59JbWatznfBpLYE4SfKmVmr810w6d8G4V5MZtbanCCSSm0vJpcgzKzF+S6Y1JYg3AZhZq3Od8HE3VzNzPryXTDJN1KPErSNchuEmbU2J4gkX4Bw6cHMzAliu3wVk9sfzMycILbLVzG5B5OZWckJQtJpklZL6pR0ccH2vSXdIGmppBWS5qT1R0takvt5RtKHyoy1bxWT2x/MzEp7JrWkNuAy4I1AF7BI0oKIWJnb7QJgZUScKakDWC3p6ohYDRyXe59HgOvLihWy6b73GD2KrT0Vt0GYmVFuCWIG0BkRayJiG3ANMKtmnwAmSBIwHtgI9NTsMxO4PyIeKjFWKhHs1d4GuA3CzAzKTRCTgbW55a60Lm8ecAywDlgGXBgRlZp9ZgPfGegkks6TtFjS4vXr1w852ErAnmOyBOEShJlZuQmiqCK/ZkILTgWWAAeRVSnNkzRx+xtI7cBbgO8NdJKIuDwipkfE9I6OjiEHW6kEe6YSxBg/Tc7MrNQE0QUcnFueQlZSyJsDXBeZTuABYGpu++nA3RHxWIlxAtUqpqxJxiUIM7NyE8Qi4EhJh6eSwGxgQc0+D5O1MSBpEnA0sCa3/WwGqV4aTr2VcBWTmVlOab2YIqJH0lzgRqANuDIiVkg6P22fD1wCXCVpGVmV1EURsQFA0l5kPaD+qqwY+8bL9iomN1KbmZWYIAAiYiGwsGbd/NzrdcApAxy7Bdi/zPjyKpEvQbgNwszMX5WT3ghGt4kxbfLT5MzMqCNBSDpD0m5/x4yAURJjR7e5DcLMjPpKELOB30r6R0nHlB1Qs/RWglGCPcaMchuEmRl1JIiIeDfwcuB+4D8k3ZEGp00oPboGqkQwapR46eS9OfoFu9VHMzMbkroaqSPiGUk/APYEPgS8FfiYpK9ExFdLjK9hqlVM/zFnRrNDMTMbEeppgzhT0vXAz4ExwIyIOB04FvhoyfE1TG8laJN7L5mZVdVTgng78M8RcWt+ZURskfSX5YTVeFkVU7OjMDMbOepJEJ8BHq0uSNoTmBQRD0bEz0qLrMEqEcglCDOz7er5zvw9ID/Dai+DTJ73h6oSuIrJzCynngQxOj3PAYD0ur28kJqjElk3VzMzy9STINZLekt1QdIsYEN5ITVHbyXr5mpmZpl62iDOB66WNI9sQr21wDmlRtUE1W6uZmaW2WmCiIj7gRMkjQcUEc+WH1bjVUdSm5lZpq6BcpLeDLwYGFvt6RMRf19iXA1XHUltZmaZegbKzQfeAXyArIrp7cChJcfVcK5iMjPrq55G6j+JiHOAJyPi74BX0fdRoruF3vBIajOzvHoSxPPp3y2SDgK6gcPLC6k53M3VzKyvetogbpC0D/BF4G4ggCvKDKrRIoIIPJLazCxn0BJEelDQzyLiqYj4AVnbw9SI+Nt63lzSaZJWS+qUdHHB9r0l3SBpqaQVkubktu0j6fuSVkm6T9KrdvGz1a0S2b9tLkKYmW03aIKIiApwaW55a0Q8Xc8bS2oDLgNOB6YBZ0uaVrPbBcDKiDgWOAm4VFJ1lPaXgZ9ExFSymWPvq+e8Q1GJLEM4P5iZ7VBPG8RNks7Srte/zAA6I2JNmp7jGmBWzT4BTEjvPR7YCPRImgicCPw7ZNN7RMRTu3j+uvWmIoS7uZqZ7VBPG8RHgHFkN+7nybq6RkRM3Mlxk8lGXVd1AX9cs888YAGwDpgAvCMiKpKOANaTPcHuWOAu4MKI2Fx7EknnAecBHHLIIXV8nP5SAcLdXM3Mcup55OiEiBgVEe0RMTEt7yw5QJZI+r1dzfKpwBLgIOA4YF4qPYwGjge+FhEvBzYD/dowUnyXR8T0iJje0dFRR1j99bqKycysn52WICSdWLS+9gFCBbroO15iCllJIW8O8PmICKBT0gPAVOBhoCsifpX2+z4DJIjhsKMNwhnCzKyqniqmj+VejyVrW7gLeMNOjlsEHCnpcOARYDbwzpp9HgZmArdJmgQcDayJiA2S1ko6OiJWp31W1hHrkER62oUThJnZDvVM1ndmflnSwcA/1nFcj6S5wI1AG3BlRKyQdH7aPh+4BLhK0jKyKqmLIqI6lfgHyGaRbQfWkJU2SuEqJjOz/uqarK9GF/CSenaMiIXAwpp183Ov1wGnDHDsEmD6EOLbZdUqJo+DMDPboZ42iK+yo3F5FFlj8tISY2q4aoLwSGozsx3qKUEszr3uAb4TEb8sKZ6mqKQ2CJcgzMx2qCdBfB94PiJ6IRshLWmviNhSbmiN45HUZmb91TOS+mfAnrnlPYH/Liec5qiOpHYVk5nZDvUkiLERsam6kF7vVV5IjVcdSe3nQZiZ7VBPgtgs6fjqgqRXAM+VF1Ljba9iqudqmJm1iHraID4EfE9SdRT0gWSPIN1t9HoktZlZP/UMlFskaSrZKGcBqyKiu/TIGiicIMzM+tlppYqkC4BxEbE8IpYB4yX9TfmhNU6vp9owM+unnlr39+efxRARTwLvLy2iJtgxkrrJgZiZjSD13BJH5R8WlJ4U1z7I/n9wPJLazKy/ehqpbwSulTSfbMqN84H/KjWqBts+ktoJwsxsu3oSxEVkT2z7a7JG6nvIejLtNtzN1cysv3qeKFcB7iSbcns62bMZ7is5robqdRWTmVk/A5YgJB1F9pCfs4EngO8CRMTrGxNa41S7ubqKycxsh8GqmFYBtwFnRkQngKQPNySqBktTMbmbq5lZzmBVTGcBvwP+R9IVkmaStUHsdqqT9bkNwsxshwFviRFxfUS8A5gK3Ax8GJgk6WuSCp8C94eq4pHUZmb91NNIvTkiro6IM4ApwBLg4rIDa6SKR1KbmfWzS5UqEbExIv4tIt5Qz/6STpO0WlKnpH5JRdLekm6QtFTSCklzctselLRM0hJJi2uPHU4eSW1m1l894yCGJI24vgx4I9AFLJK0ICJW5na7AFgZEWdK6gBWS7o6Iral7a+PiA1lxVjlkdRmZv2V+Z15BtAZEWvSDf8aYFbNPgFMSFN5jAc2kj33uqEq7uZqZtZPmQliMrA2t9yV1uXNA44B1gHLgAvTwDzIksdNku6SdN5AJ5F0nqTFkhavX79+SIG6DcLMrL8yE0TR3TZqlk8la/Q+CDgOmCdpYtr26og4HjgduEDSiUUniYjLI2J6REzv6OgYUqA7RlIP6XAzs91SmQmiCzg4tzyFrKSQNwe4LjKdwANk3WqJiHXp38eB68mqrEqxfST1KGcIM7OqMhPEIuBISYdLaiebtmNBzT4Pk83thKRJZE+tWyNpnKQJaf044BRgeVmBeiS1mVl/pfViiogeSXPJpgtvA66MiBWSzk/b5wOXAFdJWkZWJXVRRGyQdARwfepVNBr4dkT8pKxYqyOp3c3VzGyH0hIEQEQsBBbWrJufe72OrHRQe9wa4NgyY8tzN1czs/78nRlPtWFmVsQJAj9RzsysiBME+SqmJgdiZjaCOEGQf+SoM4SZWZUTBDu6ubqKycxsBycIcg8Mcn4wM9vOCYIdI6ldxWRmtoMTBB5JbWZWxAkCVzGZmRVxgsC9mMzMijhB4JHUZmZFnCBwN1czsyJOEHgktZlZEScIoFJxFZOZWS0nCHJVTG6kNjPbzgkCd3M1MyviBEE2klryA4PMzPKcIMiqmNz+YGbWV6kJQtJpklZL6pR0ccH2vSXdIGmppBWS5tRsb5N0j6QflRlnb4Srl8zMapSWICS1AZcBpwPTgLMlTavZ7QJgZUQcC5wEXCqpPbf9QuC+smKsqkS4BGFmVqPMEsQMoDMi1kTENuAaYFbNPgFMUFb5Px7YCPQASJoCvBn4eokxZkG4isnMrJ8yE8RkYG1uuSuty5sHHAOsA5YBF0ZEekI0/wL8b6DCICSdJ2mxpMXr168fUqC9lXAXVzOzGmUmiKI7btQsnwosAQ4CjgPmSZoo6Qzg8Yi4a2cniYjLI2J6REzv6OgYUqCV1IvJzMx2KDNBdAEH55ankJUU8uYA10WmE3gAmAq8GniLpAfJqqbeIOk/ywq0UnEbhJlZrTITxCLgSEmHp4bn2cCCmn0eBmYCSJoEHA2siYiPR8SUiDgsHffziHh3WYFWwqOozcxqjS7rjSOiR9Jc4EagDbgyIlZIOj9tnw9cAlwlaRlZldRFEbGhrJgGUnE3VzOzfkpLEAARsRBYWLNufu71OuCUnbzHzcDNJYS3nbu5mpn155HUQKXibq5mZrWcIPBIajOzIk4QpComZwgzsz6cIPBIajOzIk4QZCOpXYAwM+vLCQJXMZmZFXGCwN1czcyKOEGQdXNtc4IwM+vDCQJP1mdmVsQJAlcxmZkVcYLAk/WZmRVxgsDdXM3MijhB4G6uZmZFnCDwSGozsyJOELiKycysiBME7sVkZlbECQInCDOzIk4QuJurmVmRUhOEpNMkrZbUKenigu17S7pB0lJJKyTNSevHSvp1bv3flRmnR1KbmfVXWoKQ1AZcBpwOTAPOljStZrcLgJURcSxwEnCppHZgK/CGtP444DRJJ5QVa6XiKiYzs1plliBmAJ0RsSYitgHXALNq9glggiQB44GNQE9kNqV9xqSfKCtQVzGZmfVXZoKYDKzNLXeldXnzgGOAdcAy4MKIqEBWApG0BHgc+GlE/KroJJLOk7RY0uL169cPKVB3czUz66/MBFF0y60tBZwKLAEOIqtKmidpIkBE9EbEccAUYIaklxSdJCIuj4jpETG9o6NjSIG6F5OZWX9lJogu4ODc8hSykkLeHOC6VKXUCTwATM3vEBFPATcDp5UVqEdSm5n1V2aCWAQcKenw1PA8G1hQs8/DwEwASZOAo4E1kjok7ZPW7wmcDKwqK9DeCEa5w6+ZWR+jy3rjiOiRNBe4EWgDroyIFZLOT9vnA5cAV0laRlYldVFEbJD0MuAbqSfUKODaiPhRWbG6isnMrL/SEgRARCwEFtasm597vQ44peC4e4GXlxlbnru5mpn154oV3M3VzKyIEwQeSW1mVsQJAlcxmZkVcYIgVTE5QZiZ9eEEgbu5mpkV8W0RCHdzNTPrxwmCrIrJCcLMrC8nCDxZn5lZEScI0khqZwgzsz6cIHA3VzOzIk4QVNsgmh2FmdnI4gQBnPriSUw7aGKzwzAzG1FKnazvD8W/zG7YvIBmZn8wXIIwM7NCThBmZlbICcLMzAo5QZiZWSEnCDMzK+QEYWZmhZwgzMyskBOEmZkVUkQ0O4ZhI2k98NAuHnYAsKGEcIbDSI1tpMYFIzc2x7XrRmpsIzUuGFpsh0ZER9GG3SpBDIWkxRExvdlxFBmpsY3UuGDkxua4dt1IjW2kxgXDH5urmMzMrJAThJmZFXKCgMubHcAgRmpsIzUuGLmxOa5dN1JjG6lxwTDH1vJtEGZmVswlCDMzK+QEYWZmhVo6QUg6TdJqSZ2SLm5iHAdL+h9J90laIenCtP6zkh6RtCT9vKlJ8T0oaVmKYXFat5+kn0r6bfp33wbHdHTuuiyR9IykDzXrmkm6UtLjkpbn1g14jSR9PP3drZZ0aoPj+qKkVZLulXS9pH3S+sMkPZe7dvMbHNeAv7tGXa9BYvtuLq4HJS1J6xt5zQa6T5T3dxYRLfkDtAH3A0cA7cBSYFqTYjkQOD69ngD8BpgGfBb46Ai4Vg8CB9Ss+0fg4vT6YuALTf5d/g44tFnXDDgROB5YvrNrlH63S4E9gMPT32FbA+M6BRidXn8hF9dh+f2acL0Kf3eNvF4DxVaz/VLgb5twzQa6T5T2d9bKJYgZQGdErImIbcA1wKxmBBIRj0bE3en1s8B9wORmxLILZgHfSK+/Afxp80JhJnB/ROzqKPphExG3AhtrVg90jWYB10TE1oh4AOgk+3tsSFwRcVNE9KTFO4EpZZx7V+MaRMOu185ikyTgz4HvlHX+gQxynyjt76yVE8RkYG1uuYsRcFOWdBjwcuBXadXcVBVwZaOrcXICuEnSXZLOS+smRcSjkP3hAn/UpNgAZtP3P+xIuGYw8DUaSX97fwn8V275cEn3SLpF0mubEE/R724kXa/XAo9FxG9z6xp+zWruE6X9nbVyglDBuqb2+ZU0HvgB8KGIeAb4GvBC4DjgUbKibTO8OiKOB04HLpB0YpPi6EdSO/AW4Htp1Ui5ZoMZEX97kj4J9ABXp1WPAodExMuBjwDfljSxgSEN9LsbEdcrOZu+X0Yafs0K7hMD7lqwbpeuWysniC7g4NzyFGBdk2JB0hiyX/rVEXEdQEQ8FhG9EVEBrqDEYvVgImJd+vdx4PoUx2OSDkyxHwg83ozYyJLW3RHxWIpxRFyzZKBr1PS/PUnvAc4A3hWpwjpVRTyRXt9FVmd9VKNiGuR31/TrBSBpNPBnwHer6xp9zYruE5T4d9bKCWIRcKSkw9O30NnAgmYEkuo1/x24LyL+Kbf+wNxubwWW1x7bgNjGSZpQfU3WwLmc7Fq9J+32HuD/NTq2pM83upFwzXIGukYLgNmS9pB0OHAk8OtGBSXpNOAi4C0RsSW3vkNSW3p9RIprTQPjGuh319TrlXMysCoiuqorGnnNBrpPUObfWSNa30fqD/Amsp4A9wOfbGIcryEr+t0LLEk/bwK+BSxL6xcABzYhtiPIekIsBVZUrxOwP/Az4Lfp3/2aENtewBPA3rl1TblmZEnqUaCb7Jvbewe7RsAn09/dauD0BsfVSVY3Xf1bm5/2PSv9jpcCdwNnNjiuAX93jbpeA8WW1l8FnF+zbyOv2UD3idL+zjzVhpmZFWrlKiYzMxuEE4SZmRVygjAzs0JOEGZmVsgJwszMCjlBWEuTtCn3+k1pRsxDavY5V1JF0sty65an6Q4Ge++vS5q2k32ukvS2IYZvVionCDNA0kzgq8BpEfFwwS5dZH3K6xYR74uIlcMRX5E0stesNE4Q1vLSBGtXAG+OiPsH2O1HwIslHV1w/CmS7pB0t6TvpblykHSzpOnp9Xsl/Satu0LSvNxbnCzptrT9jLT/WEn/oew5HPdIen1af246xw1kEygeKOnW9CyC5U2aYM92U04Q1ur2IJua4E8jYtUg+1XI5t3/RH6lpAOATwEnRzah4WKySdvy+xwEfBo4AXgjMLXmvQ8DXge8GZgvaSxwAUBEvJRsOpFvpPUArwLeExFvAN4J3BgRxwHHko2uNRsWThDW6rqB28mmetiZbwMnpHltqk4gezDLL5U9Zew9ZA8uypsB3BIRGyOimx0zz1ZdGxGVyKaQXkOWQF5DNvUEKXE9xI5J4H4aEdXnFSwC5kj6LPDSyJ4TYDYsnCCs1VXIHgDzSkmfGGzHyB6ycynZRHdVIrthH5d+pkVEbbIpmna5z1sXLA92zOZcTLeSPQHtEeBbks7ZybnM6uYEYS0vshlNzwDeJWlnJYmryGb17EjLdwKvlvQiAEl7Saqd7vnXwOsk7Zsals+q2f52SaMkvZBscsTVwK3Au9J7HgUcktb3IelQ4PGIuIJsps/j6/jIZnVxLwgzICI2pmmwb5W0ISIKpy+PiG2SvgJ8OS2vl3Qu8B1Je6TdPkU2S3D1mEck/QPZ07/WASuBp3Nvuxq4BZhENlvo85L+law9YhnZQ33OjYit2YzPfZwEfExSN7AJcAnCho1nczVrAEnjI2JTKkFcD1wZEdc3Oy6zwbiKyawxPpsasZcDDwA/bGo0ZnVwCcLMzAq5BGFmZoWcIMzMrJAThJmZFXKCMDOzQk4QZmZW6P8DdX0wKae98HAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scores = []\n",
    "k_values = list(range(1, 200, 1))\n",
    "print(k)\n",
    "for k in range(1, 200, 1):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    classifier.fit(train_data, train_labels)\n",
    "    scores.append(classifier.score(test_data, test_labels))\n",
    "\n",
    "plt.plot(range(1, 200, 1), scores)\n",
    "plt.title('Viral Tweets as Top 10%')\n",
    "plt.xlabel('K Neigbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('Top_10.jpg')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The classifier gets better as `k` increases, but as `k` gets too high, underfitting starts to happen. That why I should try to have lowest k value, with highest accuracy score.\n",
    "\n",
    "By using the features `tweet_length`, `followers_count`,`friends_count`, `hashtag_count` and `link_count`, I was able to get up to around 60% accuracy classyfing viral tweets as these above median. That is better than random, but still not exceptional. Although if I would like to classify more distinct, let's say top 10% as viral, results get even better, which makes sense. It is easier to classify them as they are more different. In this case Accuracy is almost 90%. That's very good result!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e925636a0b7c6026e16ceba626bc40dea2d843d871da5cfe06b4755fd84dac6a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
